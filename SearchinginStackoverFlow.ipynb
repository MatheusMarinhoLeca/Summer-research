{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8319e334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'Algorithmic' on site 'stackoverflow'...\n",
      "Found 0 results for 'Algorithmic' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Fairness' on site 'stackoverflow'...\n",
      "Post ID: 64841211\n",
      "Post URL: https://stackoverflow.com/questions/64841211/mvar-fairness-guarantees\n",
      "Original Question: MVar fairness guarantees?\n",
      "Full Question: I'm building a thread-safe shared state with MVar and due to requirements I need some fairness guarantees (If two threads asked a state under MVar one after the other then as soon as the state is available the threads will take it in the order they asked for it).\n",
      "I didn't find any note in the MVar documentation.\n",
      "So in case of fairness guarantees is it required to build some sort of a wrapper of ReentrantLock(true) fair lock?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2020-11-15 06:31:31\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 72\n",
      "Tags: scala, concurrency, functional-programming, scala-cats\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 46252443\n",
      "Post URL: https://stackoverflow.com/questions/46252443/semaphore-fairness-setting\n",
      "Original Question: Semaphore fairness setting\n",
      "Full Question: I am trying the understand the fairness setting of Semaphore(int num, boolean how).\n",
      "I have this program.Where the fairness setting seems to be not working.\n",
      "public static void main(String[] args) throws InterruptedException {\n",
      "\n",
      "\n",
      "        shared sh=new shared();\n",
      "        Semaphore sm=new Semaphore(1,true);\n",
      "        newthread1 nh1=new  newthread1(sm,sh,\"nh1\");\n",
      "\n",
      "        newthread1 nh3=new newthread1(sm, sh,\"nh3\");\n",
      "        newthread1 nh2=new newthread1(sm, sh,\"nh2\");\n",
      "        }\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Class shared:-\n",
      "\n",
      "public class shared {\n",
      "\n",
      "    public void msg()\n",
      "    {\n",
      "        for(int i=65;i<68;i++) {\n",
      "            System.out.println(Thread.currentThread().getName()+ \" \" + (char)i);\n",
      "\n",
      "        }\n",
      "    }\n",
      "\n",
      "}\n",
      "\n",
      "    class new thread:-\n",
      "import java.util.concurrent.*;\n",
      "public class newthread1 implements Runnable  {\n",
      "    shared sh=null;\n",
      "    Semaphore sem=null;\n",
      "    Thread t=null;\n",
      "    String name=null;\n",
      "    public newthread1(Semaphore sem,shared sh,String name) {\n",
      "        // TODO Auto-generated constructor stub\n",
      "        this.sem=sem;\n",
      "        this.sh=sh;\n",
      "        this.name=name;\n",
      "\n",
      "        t=new Thread(this,name);\n",
      "        t.start();\n",
      "    }\n",
      "\n",
      "    @Override\n",
      "    public void run() {\n",
      "\n",
      "        try {\n",
      "            sem.acquire();\n",
      "        } catch (InterruptedException e) {\n",
      "            // TODO Auto-generated catch block\n",
      "            e.printStackTrace();\n",
      "        }\n",
      "\n",
      "        System.out.println(Thread.currentThread().getName() +\" has accuqired the lock\");\n",
      "        sh.msg();\n",
      "\n",
      "        sem.release();\n",
      "        // TODO Auto-generated method stub\n",
      "\n",
      "    }\n",
      "    } \n",
      "\n",
      "Please correct my understanding here:-\n",
      "My understanding that waiting thread should get the lock,the order they have requested for lock.if i run the program  it does not give me the correct result.\n",
      "every time gives different result.\n",
      "Thank You\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2017-09-16 11:42:16\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 77\n",
      "Tags: java, multithreading\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 44964979\n",
      "Post URL: https://stackoverflow.com/questions/44964979/what-is-fairness-in-multi-threading-programming\n",
      "Original Question: What is fairness in multi-threading programming?\n",
      "Full Question: What is thread fairness or fairness in concurrent/multi-threaded programming?\n",
      "I have googled, there is loads of info on multi-threading but not exactly on fairness. \n",
      "Can some one explain. An example is most welcome.\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2017-07-07 09:28:29\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 5587\n",
      "Tags: java, multithreading, concurrency, multiprocessing\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 70320992\n",
      "Post URL: https://stackoverflow.com/questions/70320992/reentrantlock-fairness\n",
      "Original Question: ReentrantLock Fairness\n",
      "Full Question: My ReentrantLock is not working as my expectiation. I expected the result of below code to have two threads locked and unlocked randomly but I got the result was always unlock on one thread. Can anyone explain ReentrantLock and I am trying to understand the fairness policy of it (i.e. new ReentrantLock(true)) and also tryLock() method. Thanks.\n",
      "    final ReentrantLock lock = new ReentrantLock(true);\n",
      "    new Thread(new Runnable() {\n",
      "        @Override\n",
      "        public void run() {\n",
      "            while (true)\n",
      "                try{\n",
      "                    if (lock.tryLock(1, TimeUnit.SECONDS)) {\n",
      "                        lock.lock();\n",
      "                        System.out.println(Thread.currentThread().getName() + \" locked\");\n",
      "                        lock.unlock();\n",
      "                    } else {\n",
      "                        System.out.println(Thread.currentThread().getName() + \" not locked\");\n",
      "                    }\n",
      "                    Thread.sleep(1000);\n",
      "                } catch (Exception e) {\n",
      "                    e.printStackTrace();\n",
      "                }\n",
      "        }\n",
      "    }).start();\n",
      "    new Thread(new Runnable() {\n",
      "        @Override\n",
      "        public void run() {\n",
      "            while (true)\n",
      "                try{\n",
      "                    if (lock.tryLock(1, TimeUnit.SECONDS)) {\n",
      "                        lock.lock();\n",
      "                        System.out.println(Thread.currentThread().getName() + \" locked\");\n",
      "                        lock.unlock();\n",
      "                    } else {\n",
      "                        System.out.println(Thread.currentThread().getName() + \" not locked\");\n",
      "                    }\n",
      "                    Thread.sleep(1000);\n",
      "                } catch (Exception e) {\n",
      "                    e.printStackTrace();\n",
      "                }\n",
      "        }\n",
      "    }).start();\n",
      "\n",
      "Results in console:\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "Thread-1 not locked\n",
      "Thread-0 locked\n",
      "\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-12-12 06:44:56\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 61\n",
      "Tags: java, reentrantlock\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 47473650\n",
      "Post URL: https://stackoverflow.com/questions/47473650/reentrantlock-fairness-parameter\n",
      "Original Question: ReentrantLock fairness parameter\n",
      "Full Question: This question is full theoretical, I'm sorry but I cannot avoid this time.\n",
      "I'm learning about ReentrantLock and read this:\n",
      "\n",
      "Note however, that fairness of locks does not guarantee fairness of thread scheduling.\n",
      "\n",
      "What does this mean? How can I imagine this? \n",
      "Let's suppose that the lock is not held by anyone right now:\n",
      "\n",
      "thread scheduler wakes up t1 thread (who is not the longest waiting thread) \n",
      "t1 tries to acquire the lock\n",
      "lock rejects t1 because t1 is not the longest waiting thread\n",
      "t1 goes to sleep\n",
      "thread scheduler wakes up a thread\n",
      "\n",
      "Does Java work this way? In a very unsuccesful case this would mean lots of context switching (that leads to poor throughput, that is written down in the documentation).\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2017-11-24 14:47:32\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 2764\n",
      "Tags: java, multithreading, reentrantlock\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 72975183\n",
      "Post URL: https://stackoverflow.com/questions/72975183/tensorflow-fairness-indicators-for-multiclass-output\n",
      "Original Question: Tensorflow Fairness Indicators for Multiclass output\n",
      "Full Question: According to the github page for tensorflow fairness-indicators :\n",
      "\n",
      "Fairness Indicators enables easy computation of commonly-identified fairness metrics for binary and multiclass classifiers.\n",
      "\n",
      "However, I'm unable to find any example using tf-fairness-indicators for multiclass classifier/output. The examples mentioned here and here demonstrates the usage only for binary-class, without giving any idea how to extend this for multiclass-classifiers.\n",
      "Do we have any reference/documented approach for extending this to multiclass-classifiers ?\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2022-07-14 06:24:22\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 80\n",
      "Tags: tensorflow, tensorflow-model-analysis\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 47818666\n",
      "Post URL: https://stackoverflow.com/questions/47818666/fairness-in-optaplanner-but-with-hours-instead-of-shifts\n",
      "Original Question: Fairness in Optaplanner, but with hours instead of shifts\n",
      "Full Question: Im having some trouble with my fairness constraint, I want to make sure employees get:\n",
      "\n",
      "Even amount of shifts during weeks.\n",
      "Even amount of shifts in total.\n",
      "\n",
      "Basically I want to avoid that fairness is only checking weeks (so that if there's 2 extra shifts, it won't be the same two employees getting those every week, potentially)\n",
      "And I want to avoid fairness checking only the total (so that maybe one employee get much more shifts one week, then none the next, but overall theyd all still get even hours)\n",
      "So I tried to follow what the docs for Optaplanner said in regards to a fairness constraint, and made two constraints for that, but unlike the docs preview that uses shifts, I need mine to be estimated in hours... So now, my code:\n",
      "\n",
      "\n",
      "public int accumulateFairnessInHoursPerEmployeePerWeek(Week week)\n",
      "    {\n",
      "        //System.out.println(\"WEEK FAIRNESS CONSTRAINT:\");\n",
      "        int actualWorkload = 0;\n",
      "        int totalAssignmentsDuringWeek = 0;\n",
      "        for(Employee emp : getEmployees())\n",
      "        {\n",
      "            List<Assignment> assignmentsForEmployeeDuringWeek = new ArrayList<>();\n",
      "            for(Assignment currentAss : getAssignmentsForSpecificWeek(week))\n",
      "            {\n",
      "                if(currentAss.getEmployee() == emp)\n",
      "                {\n",
      "                    assignmentsForEmployeeDuringWeek.add(currentAss);\n",
      "                }\n",
      "            }\n",
      "            totalAssignmentsDuringWeek += getDurationForAssignments(assignmentsForEmployeeDuringWeek)/3600;\n",
      "            actualWorkload += (int) Math.pow(getDurationForAssignments(assignmentsForEmployeeDuringWeek)/3600, 2);\n",
      "            //System.out.println(emp.getName() + \" has \" + getDurationForAssignments(assignmentsForEmployeeDuringWeek)/3600 + \" hours. Score: \" + actualWorkload + \" total: \" + actualWorkload + \" \" + ass.getShift().getStartDate());\n",
      "         }\n",
      "        int idealWorkLoad = (int) Math.pow(totalAssignmentsDuringWeek, 2)/getEmployees().size();\n",
      "        //System.out.println(\"IDEAL: \" + idealWorkLoad + \" ACTUAL: \" + actualWorkload + \" FAIRNESS: \" + (actualWorkload -idealWorkLoad));\n",
      "        return (actualWorkload - idealWorkLoad);\n",
      "    }\n",
      "\n",
      "    public int accumulateFairnessInHoursPerEmployeeInTotal()\n",
      "    {\n",
      "        System.out.println(\"TOTAL FAIRNESS CONSTRAINT:\");\n",
      "        int actualWorkload = 0;\n",
      "        int totalDuration = 0;\n",
      "        for(Employee emp : getEmployees())\n",
      "        {\n",
      "            List<Assignment> assignmentsForEmployee = new ArrayList<>();\n",
      "            for(Assignment currentAss : getAssignments())\n",
      "            {\n",
      "                if(currentAss.getEmployee() == emp)\n",
      "                {\n",
      "                    assignmentsForEmployee.add(currentAss);\n",
      "                }\n",
      "            }\n",
      "            totalDuration += getDurationForAssignments(assignmentsForEmployee)/3600;\n",
      "            actualWorkload += (int) Math.pow(getDurationForAssignments(assignmentsForEmployee)/3600, 2);\n",
      "            System.out.println(emp.getName() + \" has \" + getDurationForAssignments(assignmentsForEmployee)/3600 + \" hours. Score: \" + actualWorkload);\n",
      "        }\n",
      "        int idealWorkLoad = (int) Math.pow(totalDuration, 2)/getEmployees().size();\n",
      "        System.out.println(\"IDEAL: \" + idealWorkLoad + \" ACTUAL: \" + actualWorkload + \" FAIRNESS: \" + (actualWorkload - idealWorkLoad));\n",
      "        return (actualWorkload - idealWorkLoad);\n",
      "    }\n",
      "\n",
      "\n",
      "\n",
      "And here's the drools:\n",
      "\n",
      "\n",
      "rule \"EvenWorkloadPerEmployeeTotal\"\n",
      "    when\n",
      "        $service : Service\n",
      "        (\n",
      "            $service.accumulateFairnessInHoursPerEmployeeInTotal() != 0\n",
      "        )\n",
      "\n",
      "    then\n",
      "        if(isDroolActivated(kcontext.getRule().getName(), $service))\n",
      "        {\n",
      "            setDroolRating(scoreHolder, kcontext, $service.getDroolStrength(drools), $service.accumulateFairnessInHoursPerEmployeeInTotal());\n",
      "        }\n",
      "end\n",
      "\n",
      "rule \"EvenWorkloadPerEmployeePerWeek\"\n",
      "    when\n",
      "        $week : Week()\n",
      "        $service : Service\n",
      "        (\n",
      "            $service.accumulateFairnessInHoursPerEmployeePerWeek($week) != 0\n",
      "        )\n",
      "\n",
      "    then\n",
      "        if(isDroolActivated(kcontext.getRule().getName(), $service))\n",
      "        {\n",
      "            setDroolRating(scoreHolder, kcontext, $service.getDroolStrength(drools), $service.accumulateFairnessInHoursPerEmployeePerWeek($week));\n",
      "        }\n",
      "end\n",
      "\n",
      "\n",
      "\n",
      "It seemingly works most of the time, especially in smaller datasets... However, when I use a bigger dataset...\n",
      "This is my results:\n",
      "\n",
      "\n",
      "A has 76.0 hours. Score: 5776 \n",
      "B has 118.0 hours. Score: 19700\n",
      "C has 76.0 hours. Score: 25476\n",
      "D has 83.0 hours. Score: 32365\n",
      "E has 88.0 hours. Score: 40109\n",
      "F has 72.0 hours. Score: 45293\n",
      "G has 68.0 hours. Score: 49917\n",
      "H has 64.0 hours. Score: 54013\n",
      "I has 96.0 hours. Score: 63229\n",
      "J has 94.0 hours. Score: 72065\n",
      "K has 92.0 hours. Score: 80529\n",
      "L has 67.0 hours. Score: 85018\n",
      "M has 98.0 hours. Score: 94622\n",
      "N has 95.0 hours. Score: 103647\n",
      "O has 101.0 hours. Score: 113848\n",
      "P has 90.0 hours. Score: 121948\n",
      "Q has 93.0 hours. Score: 130597\n",
      "R has 108.0 hours. Score: 142261\n",
      "S has 124.0 hours. Score: 157637\n",
      "T has 116.0 hours. Score: 171093\n",
      "\n",
      "IDEAL: 157560 ACTUAL: 171093 FAIRNESS: 13533\n",
      "The numbers go pretty high...\n",
      "And I doubt anyone finds it fair that G and H gets only 64-68 hours, but S must work for 124 hours\n",
      "I'm wondering if theres another/better way to estimate fairness when using time instead of shifts to calculate fairness?\n",
      "EDIT: Probably worth noting that I tried with days as well, but the numbers seemed far too small using those, it was like it didn't care much for a single day too much on one employee compared to another.\n",
      "I'm using these constraints at the same time, but not with other constraints involved\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2017-12-14 19:05:10\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 482\n",
      "Tags: java, optaplanner\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 61588711\n",
      "Post URL: https://stackoverflow.com/questions/61588711/optaplanner-employee-fairness-calculation\n",
      "Original Question: optaplanner employee fairness calculation\n",
      "Full Question: How to calculate fairness of employee using Constraint streams api.\n",
      "https://www.optaplanner.org/blog/2017/02/03/FormulaForMeasuringUnfairness.html\n",
      "I have seen the above drools implementation in tennis solver example.\n",
      "https://github.com/kiegroup/optaplanner/blob/581d10fb8140f37b7491d06b2bab8d5ac940d7f6/optaplanner-examples/src/main/resources/org/optaplanner/examples/tennis/solver/tennisConstraints.drl\n",
      "In below link it was said advanced functions, such as load balancing/fairness will be implemented in future.\n",
      "How to calculate it currently using constraint streams. Is it possible to calculate?\n",
      "https://www.optaplanner.org/blog/2020/04/07/ConstraintStreams.html\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2020-05-04 11:10:06\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 376\n",
      "Tags: optaplanner\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 47347532\n",
      "Post URL: https://stackoverflow.com/questions/47347532/hazelcast-distributed-lock-fairness\n",
      "Original Question: Hazelcast distributed lock fairness\n",
      "Full Question: Is there any way to achieve hazelcast distributed lock fairness? \n",
      "It doesn't support now. \n",
      "Please advise\n",
      "Thankyou\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2017-11-17 11:42:47\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 372\n",
      "Tags: locking, hazelcast\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 65699934\n",
      "Post URL: https://stackoverflow.com/questions/65699934/reentrant-lock-condition-fairness\n",
      "Original Question: Reentrant lock condition fairness\n",
      "Full Question: I have a confusion regarding the ReentrantLock's Condition. Here is the documentation:\n",
      "\n",
      "\n",
      "Waiting threads are signalled in FIFO order.\n",
      "\n",
      "The ordering of lock reacquisition for threads returning from waiting\n",
      "methods is the same as for threads initially acquiring the lock, which\n",
      "is in the default case not specified, but for fair locks favors those\n",
      "threads that have been waiting the longest.\n",
      "\n",
      "\n",
      "\n",
      "According to the latest bullet the fairness brings a well-specified ordering of lock reaquisition on signalling.\n",
      "But what is the meaning of the first bullet Waiting threads are signalled in FIFO order? I presume in this case signalling means just \"signalling\" meaning that it \"unparks\" the thread in the order FIFO order, but the actual reaquiring order on wake up is governed by the fairness.\n",
      "There are pretty large amount of staff tied with cxq and wait queues internal to HotSpot which I don't understand well (unfortunately).\n",
      "\n",
      "QUESTION:\n",
      "Does Waiting threads are signalled in FIFO order mean that waiting threads are unparked in the same order they were parked (even though the lock itself is unfair)?\n",
      "Does fairness provides reaquisition ordering guarantees which is necessary since there is unpark-reaquire race in general case?\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2021-01-13 12:22:43\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 1278\n",
      "Tags: java, multithreading, jvm, jvm-hotspot\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 54516231\n",
      "Post URL: https://stackoverflow.com/questions/54516231/dominant-resource-fairness-in-yarn\n",
      "Original Question: Dominant Resource Fairness in YARN\n",
      "Full Question: I would like to implement Dominant Resource Fairness (DRF) or other scheduling algorithms in apache yarn. Does anybody know how to implement it? Is there any source?\n",
      "Cheers\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-02-04 14:34:06\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 224\n",
      "Tags: hadoop-yarn\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 55876548\n",
      "Post URL: https://stackoverflow.com/questions/55876548/fairness-monitor-doesnt-allow-configuration-of-maximum-records\n",
      "Original Question: Fairness Monitor Doesn&#39;t Allow Configuration of &quot;Maximum Records&quot;\n",
      "Full Question: When configuring accuracy monitor, one can specify min records and max records for metric computation; however, when configuring fairness monitor, there is only min records, and effectively it seems to be the fixed number of rows for fairness computation. Can anyone explain why fairness monitor is designed differently from accuracy monitor on this aspect?\n",
      "Thank you!\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-04-27 03:35:58\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 31\n",
      "Tags: watson-openscale\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 66574745\n",
      "Post URL: https://stackoverflow.com/questions/66574745/fairness-metrics-for-multi-class-classification\n",
      "Original Question: Fairness metrics for multi-class classification\n",
      "Full Question: Are there any metrics implemented in Fairlearn or any published papers that I can refer to for use-cases around fairness measurement of multi-class classification where the metrics are AP and not accuracy? Thanks!\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-03-11 02:15:03\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 814\n",
      "Tags: fairlearn\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 49012372\n",
      "Post URL: https://stackoverflow.com/questions/49012372/why-only-arrayblockingqueue-and-synchronousqueue-have-fairness-policy\n",
      "Original Question: Why only ArrayBlockingQueue and SynchronousQueue have fairness policy?\n",
      "Full Question: Speaking about all classes implementing interface BlockingQueue, only ArrayBlockingQueue and SynchronousQueue have fairness policy. \n",
      "Besides, it seems that in all other BlockingQueue classes \"fairness is false\" meaning that any thread blocked first would be unblocked in random order. \n",
      "So why ArrayBlockingQueue and SynchronousQueue are so special and distinct from other classes in this respect? \n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2018-02-27 17:31:46\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 156\n",
      "Tags: java, multithreading, producer-consumer, blockingqueue\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 64506977\n",
      "Post URL: https://stackoverflow.com/questions/64506977/calculate-group-fairness-metrics-with-aif360\n",
      "Original Question: Calculate group fairness metrics with AIF360\n",
      "Full Question: I want to calculate group fairness metrics using AIF360. This is a sample dataset and model, in which gender is the protected attribute and income is the target.\n",
      "import pandas as pd\n",
      "from sklearn.svm import SVC\n",
      "from aif360.sklearn import metrics\n",
      "\n",
      "df = pd.DataFrame({'gender': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "                  'experience': [0, 0.1, 0.2, 0.4, 0.5, 0.6, 0, 0.1, 0.2, 0.4, 0.5, 0.6],\n",
      "                  'income': [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1]})\n",
      "\n",
      "clf = SVC(random_state=0).fit(df[['gender', 'experience']], df['income'])\n",
      "\n",
      "y_pred = clf.predict(df[['gender', 'experience']])\n",
      "\n",
      "metrics.statistical_parity_difference(y_true=df['income'], y_pred=y_pred, prot_attr='gender', priv_group=1, pos_label=1)\n",
      "\n",
      "It throws out:\n",
      "---------------------------------------------------------------------------\n",
      "TypeError                                 Traceback (most recent call last)\n",
      "<ipython-input-7-609692e52b2a> in <module>\n",
      "     11 y_pred = clf.predict(X)\n",
      "     12 \n",
      "---> 13 metrics.statistical_parity_difference(y_true=df['income'], y_pred=y_pred, prot_attr='gender', priv_group=1, pos_label=1)\n",
      "\n",
      "TypeError: statistical_parity_difference() got an unexpected keyword argument 'y_true'\n",
      "\n",
      "Similar error for disparate_impact_ratio. It seems the data needs to be entered differently, but I have not been able to figure out how.\n",
      "\n",
      "Number of Answers: 3\n",
      "Answer: N/A\n",
      "Date: 2020-10-23 22:36:29\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 5063\n",
      "Tags: python, pandas, machine-learning, aif360\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 71591649\n",
      "Post URL: https://stackoverflow.com/questions/71591649/ratelimiting-with-fairness-sharing\n",
      "Original Question: Ratelimiting with fairness/sharing\n",
      "Full Question: I am looking at any library/implementation which implements rate-limiting like Guava ratelimiter. However I am also trying to ensure fairness.\n",
      "For example, lets say there are 3 queues Q1, Q2, Q3 each receiving messages. The processing rate of the system can only support 1000 messages per second.\n",
      "With guava I can configure a token based rate limiter that will gives a constant 1000 tokens per second. However, there is no guarantee that Q1, Q2 and Q3 will receive same number of tokens per second.\n",
      "A simple way would be to create 3 rate limiters with 1000/3 = 333 tokens per second and assign them to each queue. However, in that case, the system becomes sub-optimal.\n",
      "Is there any easy or simple way to achieve this without writing code from scratch ? Ideally I would want to limit each queue to a set rate - for example Q1 is allowed upto 100 TPS, Q2 - 200 TPS, Q3: 700 when the system is at full capacity.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2022-03-23 19:36:30\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 654\n",
      "Tags: java, guava, rate-limiting\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 52448414\n",
      "Post URL: https://stackoverflow.com/questions/52448414/configuring-fairness-monitoring-for-categorical-features\n",
      "Original Question: Configuring Fairness Monitoring for categorical features\n",
      "Full Question: When configuring fairness monitoring for a model, the prediction column only allows for integer numerical value even though the prediction label are categorical, is this an intended feature? How do I configure this for categorical feature (that is not integer)? is a manual conversion required?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2018-09-21 19:17:40\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 82\n",
      "Tags: ibm-watson, watson-openscale\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 17 results for 'Fairness' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Bias' on site 'stackoverflow'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post ID: 69604403\n",
      "Post URL: https://stackoverflow.com/questions/69604403/what-is-vertical-bias-or-horizontal-bias-used-for-in-androids-constraintla\n",
      "Original Question: What is &#39;Vertical Bias&#39; or &#39;Horizontal Bias&#39; used for in Android&#39;s &#39;ConstraintLayout&#39;?\n",
      "Full Question: I am quite new to Android development and today I wondered what the 'Vertical Bias' respectively the 'Horizontal Bias' is used for in the 'ConstraintLayout'.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-10-17 14:36:24\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 24139\n",
      "Tags: android, android-constraintlayout\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 67948404\n",
      "Post URL: https://stackoverflow.com/questions/67948404/pytorch-is-it-able-to-make-a-convolution-module-without-bias-have-bias-again\n",
      "Original Question: Pytorch: Is it able to make a convolution module without bias have bias again?\n",
      "Full Question: After instantiating a 2D convolution with conv = nn.Conv2d(8, 8, 3, bias=False), whose member bias should be None, is it able to give conv a legal bias again (whether with random initialization or determined values)?\n",
      "I observed that bias in other default convolution modules is of the type Parameter, so I suspect there are extra procedures beyond simply conv.bias = torch.tensor(...) to make the new bias legal for conv.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-06-12 13:27:05\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 2064\n",
      "Tags: python, pytorch\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 56723877\n",
      "Post URL: https://stackoverflow.com/questions/56723877/bias-reduces-accuracy\n",
      "Original Question: Bias reduces Accuracy\n",
      "Full Question: I am programming an application to recognise handwritten digits with the MNIST dataset for school, I added a bias and wanted to write that it improves accuracy but it actually didn't help. After one epoch accuracy without bias was 91.6% and with bias 91.53%. After more epochs there was not much difference. This surprised me a lot, could someone tell me why the bias doesnt help in my network? Maybe the code is wrong but I dont think so.\n",
      "import tensorflow as tf\n",
      "iN = 28*28\n",
      "hN = 150\n",
      "oN = 10\n",
      "lr = 0.2\n",
      "epochs = 15\n",
      "\n",
      "wih = tf.Variable(tf.truncated_normal((iN,hN), stddev=0.1))\n",
      "who = tf.Variable(tf.truncated_normal((hN,oN), stddev=0.1))\n",
      "\n",
      "bh = tf.Variable(tf.zeros((1,hN)))\n",
      "bo = tf.Variable(tf.zeros((1,oN)))\n",
      "\n",
      "x = tf.placeholder(tf.float32, shape=[1,28*28])\n",
      "y = tf.placeholder(tf.float32, shape=[1,10])\n",
      "\n",
      "hidden = tf.sigmoid(tf.matmul(x,wih) + bh)\n",
      "output = tf.sigmoid(tf.matmul(hidden, who) + bo)\n",
      "\n",
      "loss = tf.reduce_mean(tf.squared_difference(y, output))\n",
      "train_step = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
      "\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2019-06-23 14:27:47\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 49\n",
      "Tags: python, tensorflow, neural-network\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 49100135\n",
      "Post URL: https://stackoverflow.com/questions/49100135/error-with-bias-in-backpropagation\n",
      "Original Question: Error with bias in backpropagation\n",
      "Full Question: \n",
      "This is my nn. \n",
      "and here is the code:\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def relu(x):\n",
      "\n",
      "    x = np.where(x>=0,x,x*.1)\n",
      "    return x\n",
      "\n",
      "def deriv_relu(x):\n",
      "    x = np.where(x>=0,1,x*.1)\n",
      "    return x\n",
      "\n",
      "def bias(x):\n",
      "    e = np.ones((x.shape[0],1))\n",
      "    e1 = np.hstack((e,x))\n",
      "    return e1\n",
      "\n",
      "X = np.array([[1,1],[1,0],[0,0]]) #3,2\n",
      "\n",
      "y = np.array([[1,1,0]]).T #3,1\n",
      "\n",
      "w0 = np.random.random((2,5)) #2,5\n",
      "w1 = np.random.random((6,1)) #6,1\n",
      "\n",
      "for i in range(4):\n",
      "    l0 = X #3,2\n",
      "\n",
      "\n",
      "    h1 = relu(l0.dot(w0)) #3,5\n",
      "    h1_bias = bias(h1) #3,6\n",
      "\n",
      "    l1 = relu(h1_bias.dot(w1)) #3,1\n",
      "\n",
      "    error = y-l1 #3,1\n",
      "    delta2 = error*deriv_relu(l1) #3,1\n",
      "\n",
      "    error2 = delta2.dot(w1.T) #3,6\n",
      "\n",
      "\n",
      "    delta = error2*deriv_relu(h1_bias)#3,6\n",
      "\n",
      "\n",
      "    w1+=h1_bias.T.dot(delta2) #6,1\n",
      "    w0+=l0.T.dot(delta) # w0 is shape 2,5, because of added bias i am dead. Any help?\n",
      "\n",
      "\n",
      "for a,b in zip(l1,y):\n",
      "    print(a,b)\n",
      "\n",
      "The problem I am facing is, I added a bias neuron in hidden layer 1. When I start with backpropagation and matrix multiplications, I get in problem, because the dimensions are of course not aligned, which is of course of added bias. I am thinking how to overcome this issue. Is there a way I could do this within my code? \n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2018-03-04 22:32:32\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 152\n",
      "Tags: python, numpy, neural-network, bias-neuron\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 71189967\n",
      "Post URL: https://stackoverflow.com/questions/71189967/estimating-bias-in-r\n",
      "Original Question: Estimating Bias in R\n",
      "Full Question: Write a simulation experiment to estimate the bias of the estimator λˆ= 1/ X¯ by sampling\n",
      "using x=rexp(n,rate=5) and recording the values of 1/mean(x). You should find that the\n",
      "bias is λ/n−1. Here we’ve used λ = 5 but the result will hold for any λ.\n",
      "Here is my solution ( I dont get λ/n−1). Am I doing something wrong here?\n",
      "set.seed(1)\n",
      "lambda <- 5\n",
      "x <- rexp(n= 1e5, rate = lambda )\n",
      "samp.mean <- mean(x)\n",
      "lam.est <- 1/samp.mean\n",
      "lam.est ##4.986549\n",
      "\n",
      "bias <- abs(lambda - lam.est)\n",
      "bias ##0.01345146\n",
      "\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2022-02-20 01:08:01\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 1325\n",
      "Tags: r\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 48738404\n",
      "Post URL: https://stackoverflow.com/questions/48738404/what-is-functor-bias\n",
      "Original Question: What is functor bias?\n",
      "Full Question: Following up from C++ Functors - and their uses, I have come across 'right biased functor' and 'left biased functor'. I have tried to do some research on my own, but I am still failing to understand the difference between both, and what functor bias even is.\n",
      "Can someone please give an overview of what functor bias is, the difference between right bias and left bias, along with any examples of how this would be useful? It would be great if Scala could be used for the examples.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2018-02-12 03:34:17\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 149\n",
      "Tags: scala, functional-programming, scalaz\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 78394287\n",
      "Post URL: https://stackoverflow.com/questions/78394287/exponent-bias-or-the-subtraction-exponent-bias-for-ieee-754-floating-point-f\n",
      "Original Question: Exponent bias or the subtraction &quot;Exponent - Bias&quot; for IEEE 754 Floating Point Format\n",
      "Full Question: Currently reviewing some material and I see that in IEEE 754 floating point format it says:\n",
      "x = (-1)^S × (1 + Fraction) × 2^(Exponent - Bias)\n",
      "\n",
      "I am unclear on weather the 2^(Exponent - Bias) indicates 2 raised to the exponent bias, or the result of the bias subtracted from exponent aka exponent minus bias.\n",
      "\n",
      "I was looking at some examples and saw it says for the number 0.75, when converting it into single precision floating point encoding the exponent would be -1 + Bias, or -1 + 0111 1111. This is odd because the exponent = power + bias.\n",
      "\n",
      "However looking at this video: https://youtu.be/K1XgRO4pvFs?t=352 it somehow has the exponent part be 2 ^ (e - 127), where 127 is being subtracted. from this source: https://class.ece.iastate.edu/arun/CprE281_F05/ieee754/ie3.html#:~:text=For%20single%2Dprecision%20floating%2Dpoint,the%20exponent%20%3D%20power%20%2B%20bias, however, \"How do you find the bias exponent? For single-precision floating-point, the bias=127. For double-precision, the bias=1023. The sum of the bias and the power of 2 is the exponent that actually goes into the IEEE 754 string. Remember, the exponent = power + bias.\" What am I missing?\n",
      "\n",
      "To clarify, x = (-1)^S × (1 + Fraction) × 2^(Exponent - Bias)\n",
      "is it the exponent bias or exponent - bias?\n",
      "And why in this video https://youtu.be/K1XgRO4pvFs?t=352 was 2 ^ (e - 127) where 127 is being subtracted?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2024-04-27 11:11:17\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 57\n",
      "Tags: encoding, decimal, ieee-754, floating, ieee\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 70971630\n",
      "Post URL: https://stackoverflow.com/questions/70971630/get-bias-field-using-sitk\n",
      "Original Question: Get bias field using sitk\n",
      "Full Question: I'm trying to use sitk library to clear biased Mr image (MRI).\n",
      "I'm able to get the corrected image but can't get the bias image.\n",
      "Set the following parameters:\n",
      "shrink_factor=1,\n",
      "mask_image=mask, \n",
      "number_of_iterations=100, \n",
      "number_of_fitting_levels=4\n",
      "\n",
      "This is the code I tried\n",
      "corrected_image = corrector.Execute(image, maskImage)\n",
      "\n",
      "log_bias_field = corrector.GetLogBiasFieldAsImage(inputImage)\n",
      "bias_exp = sitk.Cast(sitk.Exp(log_bias_field), sitk.sitkFloat64)\n",
      "bias = inputImage / bias_exp\n",
      "bias = sitk.GetArrayFromImage(bias)\n",
      "bias = bias / bias.max()\n",
      "\n",
      "But I get this image:\n",
      "\n",
      "Do you know how to get the bias only?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2022-02-03 14:51:22\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 305\n",
      "Tags: python, simpleitk, mri\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 51959507\n",
      "Post URL: https://stackoverflow.com/questions/51959507/does-bias-in-the-convolutional-layer-really-make-a-difference-to-the-test-accura\n",
      "Original Question: Does bias in the convolutional layer really make a difference to the test accuracy?\n",
      "Full Question: I understand that bias are required in small networks, to shift the activation function. But in the case of Deep network that has multiple layers of CNN, pooling, dropout and other non -linear activations, is Bias really making a difference?  The convolutional filter is learning local features and for a given conv output channel same bias is used. \n",
      "This is not a dupe of this link. The above link only explains role of bias in small neural network and does not attempt to explain role of bias in deep-networks containing multiple CNN layers, drop-outs, pooling and  non-linear activation functions. \n",
      "I ran a simple experiment and the results indicated that removing bias from conv layer made no difference in final test accuracy.\n",
      "There are two models trained and the test-accuracy is almost same (slightly better in one without bias.)\n",
      "\n",
      "model_with_bias, \n",
      "model_without_bias( bias not added in conv layer)\n",
      "\n",
      "Are they being used only for historical reasons?\n",
      "If using bias provides no gain in accuracy, shouldn't we omit them? Less parameters to learn.\n",
      "I would be thankful if someone who have deeper knowledge than me, could explain the significance(if- any) of these bias in deep networks.\n",
      "Here is the complete code and the experiment result bias-VS-no_bias experiment\n",
      "batch_size = 16\n",
      "patch_size = 5\n",
      "depth = 16\n",
      "num_hidden = 64\n",
      "\n",
      "graph = tf.Graph()\n",
      "\n",
      "with graph.as_default():\n",
      "\n",
      "  # Input data.\n",
      "  tf_train_dataset = tf.placeholder(\n",
      "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
      "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
      "  tf_valid_dataset = tf.constant(valid_dataset)\n",
      "  tf_test_dataset = tf.constant(test_dataset)\n",
      "\n",
      "  # Variables.\n",
      "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
      "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
      "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
      "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
      "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
      "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
      "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
      "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
      "      [num_hidden, num_labels], stddev=0.1))\n",
      "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
      "\n",
      "  # define a Model with bias .\n",
      "  def model_with_bias(data):\n",
      "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
      "    hidden = tf.nn.relu(conv + layer1_biases)\n",
      "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
      "    hidden = tf.nn.relu(conv + layer2_biases)\n",
      "    shape = hidden.get_shape().as_list()\n",
      "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
      "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
      "\n",
      "  # define a Model without bias added in the convolutional layer.\n",
      "  def model_without_bias(data):\n",
      "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
      "    hidden = tf.nn.relu(conv ) # layer1_ bias is not added \n",
      "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
      "    hidden = tf.nn.relu(conv) # + layer2_biases)\n",
      "    shape = hidden.get_shape().as_list()\n",
      "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
      "    # bias are added only in Fully connected layer(layer 3 and layer 4)\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
      "    return tf.matmul(hidden, layer4_weights) + layer4_biases\n",
      "\n",
      "  # Training computation.\n",
      "  logits_with_bias = model_with_bias(tf_train_dataset)\n",
      "  loss_with_bias = tf.reduce_mean(\n",
      "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits_with_bias))\n",
      "\n",
      "  logits_without_bias = model_without_bias(tf_train_dataset)\n",
      "  loss_without_bias = tf.reduce_mean(\n",
      "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_train_labels, logits=logits_without_bias))\n",
      "\n",
      "  # Optimizer.\n",
      "  optimizer_with_bias = tf.train.GradientDescentOptimizer(0.05).minimize(loss_with_bias)\n",
      "  optimizer_without_bias = tf.train.GradientDescentOptimizer(0.05).minimize(loss_without_bias)\n",
      "\n",
      "  # Predictions for the training, validation, and test data.\n",
      "  train_prediction_with_bias = tf.nn.softmax(logits_with_bias)\n",
      "  valid_prediction_with_bias = tf.nn.softmax(model_with_bias(tf_valid_dataset))\n",
      "  test_prediction_with_bias = tf.nn.softmax(model_with_bias(tf_test_dataset))\n",
      "\n",
      "  # Predictions for without\n",
      "  train_prediction_without_bias = tf.nn.softmax(logits_without_bias)\n",
      "  valid_prediction_without_bias = tf.nn.softmax(model_without_bias(tf_valid_dataset))\n",
      "  test_prediction_without_bias = tf.nn.softmax(model_without_bias(tf_test_dataset))\n",
      "\n",
      "num_steps = 1001\n",
      "\n",
      "with tf.Session(graph=graph) as session:\n",
      "  tf.global_variables_initializer().run()\n",
      "  print('Initialized')\n",
      "  for step in range(num_steps):\n",
      "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
      "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
      "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
      "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
      "    session.run(optimizer_with_bias, feed_dict=feed_dict)\n",
      "    session.run(optimizer_without_bias, feed_dict = feed_dict)\n",
      "  print('Test accuracy(with bias): %.1f%%' % accuracy(test_prediction_with_bias.eval(), test_labels))\n",
      "  print('Test accuracy(without bias): %.1f%%' % accuracy(test_prediction_without_bias.eval(), test_labels))\n",
      "\n",
      "Output:\n",
      "Initialized\n",
      "Test accuracy(with bias): 90.5%\n",
      "Test accuracy(without bias): 90.6%\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2018-08-22 05:35:42\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 29322\n",
      "Tags: python, tensorflow, deep-learning, conv-neural-network, bias-neuron\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 52014867\n",
      "Post URL: https://stackoverflow.com/questions/52014867/calculate-bias-hidden-layer\n",
      "Original Question: calculate bias hidden layer\n",
      "Full Question: I have developped in python a small code which is using 4 neurons (2 inputs, 3 neurons in hidden layer, and 1 output neuron) the code is really specific cause i wanted to understand every operation carefully.\n",
      "It works but I still have one problem with bias !\n",
      "for epoch in range(epochs):\n",
      "    layer1, predictions = predict_output_neural(features, weights_11, weights_12, weights_13, weight_ouput, bias_11, bias_12, bias_13, bias_output)\n",
      "    if epoch % 10 == 0:\n",
      "        layer1, predictions = predict_output_neural(features, weights_11, weights_12, weights_13, weight_ouput, bias_11, bias_12, bias_13, bias_output)\n",
      "        print (cost(predictions, targets))\n",
      "    \"\"\"\n",
      "        There are a lot of things to do here !\n",
      "        to do the back propagation, we will first train the ouput neural\n",
      "    \"\"\"\n",
      "    #Init gradient\n",
      "    weights_gradient_output = np.zeros(weight_ouput.shape)\n",
      "    bias_gradient_output = 0\n",
      "\n",
      "    weights_gradient_11 = np.zeros(weights_11.shape)\n",
      "    bias_gradient_11 = 0\n",
      "\n",
      "    weights_gradient_12 = np.zeros(weights_12.shape)\n",
      "    bias_gradient_12 = 0\n",
      "\n",
      "    weights_gradient_13 = np.zeros(weights_12.shape)\n",
      "    bias_gradient_13 = 0\n",
      "    #Go throught each row\n",
      "    for neural_input, feature, target, prediction in zip(layer1, features, targets, predictions):\n",
      "\n",
      "        output_error = prediction - target\n",
      "        output_delta = output_error * derivative_activation_y(prediction)\n",
      "\n",
      "        error_neural_hidden_11 = output_delta * weight_ouput[0]\n",
      "        error_neural_hidden_12 = output_delta * weight_ouput[1]\n",
      "        error_neural_hidden_13 = output_delta * weight_ouput[2]\n",
      "\n",
      "\n",
      "        error_neural_11 = error_neural_hidden_11 * derivative_activation_y(neural_input[0])\n",
      "        error_neural_12 = error_neural_hidden_12 * derivative_activation_y(neural_input[1])\n",
      "        error_neural_13 = error_neural_hidden_13 * derivative_activation_y(neural_input[2])\n",
      "\n",
      "        weights_gradient_output += neural_input * output_delta\n",
      "        #bias_output += output_delta\n",
      "\n",
      "        weights_gradient_11 += feature * error_neural_11\n",
      "        #bias_11 += error_neural_11\n",
      "\n",
      "        weights_gradient_12 += feature * error_neural_12\n",
      "        #bias_12 += error_neural_12\n",
      "\n",
      "        weights_gradient_13 += feature * error_neural_13\n",
      "        #bias_13 += error_neural_13\n",
      "\n",
      "\n",
      "    #Update the weights and bias\n",
      "    weight_ouput = weight_ouput - (learning_rate * weights_gradient_output)\n",
      "    bias_output = bias_output - (learning_rate * bias_gradient_output)\n",
      "    weights_11 =  weights_11 - (learning_rate * weights_gradient_11)\n",
      "    bias_11 =  bias_11 - (learning_rate * bias_gradient_11)\n",
      "    weights_12 =  weights_12 - (learning_rate * weights_gradient_12)\n",
      "    bias_12 =  bias_12 - (learning_rate * bias_gradient_12)\n",
      "    weights_13 =  weights_13 - (learning_rate * weights_gradient_13)\n",
      "    bias_13 =  bias_13 - (learning_rate * bias_gradient_13)\n",
      "\n",
      "This is giving me good results, but as soon as I uncomment lines where I modify the bias of each neurons, it goes super wrong ! It converges to 0.5 (like 0,4999999)\n",
      "Do you know why ? it looks like the update of the bias gradient is good, isnt it ?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2018-08-25 09:05:50\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 192\n",
      "Tags: python, python-3.x, machine-learning, neural-network, deep-learning\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 59493570\n",
      "Post URL: https://stackoverflow.com/questions/59493570/deciding-on-a-bias-input\n",
      "Original Question: Deciding on a bias input\n",
      "Full Question: I am practicing with different network layers. Different bias inputs give different results. \n",
      "How one can find the best bias input to a DNN model? Which factors should be considered?\n",
      "I have always seen linear transformations, is there a reason for this?\n",
      "Thanks.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-12-26 23:20:06\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 38\n",
      "Tags: python, tensorflow, neural-network\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 67586937\n",
      "Post URL: https://stackoverflow.com/questions/67586937/add-bias-output-in-keras\n",
      "Original Question: Add bias output in Keras\n",
      "Full Question: I'm solving a multi-class image classification problem. Training a CNN directly did not give good results for the task, so I'm now attempting a workaround. The idea is to train multiple binary classification networks, one for each image class, and then to merge their outputs. The output layer of the merged model should be a vector of N+1 elements, where N is the number of image classes. The argmax of the output vector is the classification result (image class). The first element of the output vector is a bias term that is only activated if the image fits in none of the classes with high probability. This element is going to have a constant (bias) value in the output vector, which will serve as a  classification confidence threshold.\n",
      "I managed to do what I want by adding another input to the network; this input is initialized to a constant value and serves as the bias. Is it possible to what I want without changing the input shape of the network, by somehow embedding the constant value in the network itself?\n",
      "This is my code so far:\n",
      "inputs = Input(shape=(240, 320), name=\"img_input\")\n",
      "x = tf.keras.layers.Flatten()(inputs)\n",
      "\n",
      "outputs1 = Dense(1, activation='sigmoid')(x)\n",
      "outputs2 = Dense(1, activation='sigmoid')(x)\n",
      "\n",
      "bias = Input(shape=(1,), name=\"bias_input\")\n",
      "merged = Concatenate()([bias, outputs1, outputs2])\n",
      "model = Model(inputs=[inputs, bias], outputs=merged)\n",
      "\n",
      "print(model.summary())\n",
      "plot_model(model, to_file='network.png', show_shapes=True)\n",
      "\n",
      "\n",
      "Testing the model:\n",
      "data = np.ones(320 * 240).reshape((1, 240, 320))\n",
      "bias = (np.ones(1) / 2.0).reshape((1, 1)) # use 1.0/2 as the bias value\n",
      "# prints [[0.5 1.  1. ]] as expected\n",
      "print(model.predict({\"img_input\": data, \"bias_input\": bias}))\n",
      "\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-05-18 15:11:53\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 1750\n",
      "Tags: tensorflow, keras, conv-neural-network\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 44883861\n",
      "Post URL: https://stackoverflow.com/questions/44883861/initial-bias-values-for-a-neural-network\n",
      "Original Question: Initial bias values for a neural network\n",
      "Full Question: I am currently building a CNN in tensorflow and I am initialising my weight matrix using a He normal weight initialisation. However, I am unsure how I should initialise my bias values. I am using ReLU as my activation function between each convolutional layer. Is there a standard method to initialising bias values?\n",
      "# Define approximate xavier weight initialization (with RelU correction described by He)\n",
      "def xavier_over_two(shape):\n",
      "    std = np.sqrt(shape[0] * shape[1] * shape[2])\n",
      "    return tf.random_normal(shape, stddev=std)\n",
      "\n",
      "def bias_init(shape):\n",
      "    return #???\n",
      "\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2017-07-03 12:58:07\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 16966\n",
      "Tags: machine-learning, tensorflow, bias-neuron\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 13 results for 'Bias' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Ethics' on site 'stackoverflow'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post ID: 66072158\n",
      "Post URL: https://stackoverflow.com/questions/66072158/cleaning-data-in-a-column-using-sql\n",
      "Original Question: Cleaning data in a column using SQL\n",
      "Full Question: I have a column titled \"Keywords\" that has the keywords associated with each article that is in my dataset. I wrote a query to group the articles according to their keyword so I can make a simple visualization showing which keyword is used the most. The issue is, some of the articles have a secondary keywords, and I need to write a query to filter out those secondary keywords so that just the main one remains. For instance, the \"Keywords\" column looks like this:\n",
      "KEYWORDS\n",
      "\n",
      "Policy/Ethics\n",
      "Policy/Ethics\n",
      "Policy/Ethics: Employment\n",
      "Policy/Ethics\n",
      "Policy/Ethics: Business\n",
      "\n",
      "I need help writing a query that would keep the main keywords (Policy/Ethics), but get rid of the secondary ones. I think I use CASE for this, but I'm not sure or where to begin. Any help I could get would be greatly appreciated!\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-02-06 01:56:03\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 133\n",
      "Tags: mysql, data-cleaning\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 49450740\n",
      "Post URL: https://stackoverflow.com/questions/49450740/ethics-and-readability-of-using-ternary-operator-for-method-calls\n",
      "Original Question: Ethics and readability of using ternary operator for method calls\n",
      "Full Question: The standard use of the ternary operator is, i.e.:\n",
      "a = 1 if some_condition else 2\n",
      "\n",
      "Just today, I realized something like this is perfectly legal:\n",
      "do_something() if some_condition else do_something_else()\n",
      "\n",
      "For example:\n",
      "print(1) if a == 1 else print(2)\n",
      "\n",
      "instead of:\n",
      "if a == 1:\n",
      "    print(1)\n",
      "else:\n",
      "    print(2)\n",
      "\n",
      "In my opinion, this is more compact, readable and prettier. I see that it would be harder to get return values from this type of expression (perhaps the way would be to wrap everything in parentheses). What do you think?\n",
      "P.S. I know it's not typical Q&A content, but I have never even seen this use of the ternary operator mentioned, and I think it clearly improves some aspects of Python coding.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2018-03-23 15:26:44\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 481\n",
      "Tags: python, ternary-operator\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 66697882\n",
      "Post URL: https://stackoverflow.com/questions/66697882/adding-text-to-target-node-in-gephi-graph\n",
      "Original Question: Adding text to target node in gephi graph\n",
      "Full Question: I am trying to create a network of given data, in which source node(tweetid) target node(tweet has a link to another platform like news, youtube) edge type(a type of link like morality & ethics). I have created a network, and different indicates the different edge types morality & ethics and clustered point show twitter, news, youtube, others.\n",
      "target node\n",
      "id\n",
      "facebook     \n",
      "news\n",
      "twitter\n",
      "news\n",
      "news\n",
      "news\n",
      "\n",
      " source node\n",
      " 1194697388650370000    \n",
      " 1195602298237540000\n",
      " 1195667383182130000\n",
      " 1195673938459790000\n",
      " 1195689221970910000\n",
      "\n",
      " Edge file\n",
      " source target               edgeType \n",
      " 1194697388650370000    facebook None \n",
      " 1195602298237540000    news     None \n",
      " 1195667383182130000    Instagram Morality & Ethics \n",
      " 1195673938459790000    news     None \n",
      " 1195689221970910000    news     None\n",
      "\n",
      "\n",
      "Now, I want the highlight the target node (converging point) with a name like news, Instagram.\n",
      "How can I do it in Gephi?\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2021-03-18 21:29:56\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 383\n",
      "Tags: python, r, gephi, social-media, network-analysis\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 56625552\n",
      "Post URL: https://stackoverflow.com/questions/56625552/php-extract-second-last-value-in-array\n",
      "Original Question: PHP - Extract second last value in array\n",
      "Full Question: I have the following array:\n",
      "[\"theme\",\"1,strand\",\"Medical Ethics and Law,strandyear\",\"Year 3\"]\n",
      "\n",
      "How can I extract the second last value in the array, then the second part of that value after the comma e.g. \"Medical Ethics and Law,strandyear\"? \n",
      "This should result, for example, in 'strandyear'.\n",
      "The actual value, not the position from the end, will be different for other arrays.\n",
      "PHP 5.3.3...\n",
      "\n",
      "Number of Answers: 6\n",
      "Answer: N/A\n",
      "Date: 2019-06-17 08:10:02\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 2596\n",
      "Tags: php\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 58037099\n",
      "Post URL: https://stackoverflow.com/questions/58037099/extract-all-individual-addresses-from-a-geographical-area-includs-an-ethics-que\n",
      "Original Question: Extract all individual addresses from a geographical area (includs an ethics question)\n",
      "Full Question: Currently based in Australia, I am conducting a social research through my university. I would ideally like to access a random sample of a population - determined by a geographical area on Google Maps, OSM or other. To really have a random sample (and not self-selected volunteers answering advertisement), the only way to do so would be to have a list of all postal addresses in the said area. And pro-actively contact the selected sample within those addresses.\n",
      "Here are my questions :\n",
      "\n",
      "Is that technically feasible?\n",
      "\n",
      "If yes, would that be legal anyway? As it might be web-scraping or considered intrusive\n",
      "\n",
      "\n",
      "This question is probably going to sound very naïve - and I think I already know the answer - but I would like to confirm with more experienced people. To feel more confident saying that a 'strictly random' sample cannot be obtained ethically, and that I will need to go for a good representative sample instead.\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2019-09-21 05:46:14\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 95\n",
      "Tags: google-maps, random, openstreetmap\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 56272582\n",
      "Post URL: https://stackoverflow.com/questions/56272582/typeerror-elements-map-is-not-a-function-even-though-elements-is-an-array\n",
      "Original Question: TypeError: elements.map is not a function, even though elements is an array?\n",
      "Full Question: TypeError: elements.map is not a function.Here, elements is an array, \n",
      "function ListSelectCourses(props){\n",
      "\n",
      "    const elements = props.elements;\n",
      "    console.log(Array.isArray(elements))\n",
      "    const listElements = elements.map((element) =>\n",
      "    <option key = {element.catalog_num}>\n",
      "        {element.catalog_num}\n",
      "    </option>\n",
      "    );\n",
      "    return (\n",
      "        <h3>{props.category}\n",
      "            <select \n",
      "            value = {props.selected}\n",
      "            onChange = {props.handleChange}>\n",
      "            <option defaultValue> \n",
      "            </option>\n",
      "                {listElements}\n",
      "            </select> \n",
      "        </h3>\n",
      "    )\n",
      "};\n",
      "\n",
      "The console output is true. The data from console.log(elements): \n",
      "Array(2) \n",
      "0: {id: 190332, title: \"Legal Ethics\", term: \"2019 Fall\", school: \"LAW\", catalog_num: \"802-L\", …} \n",
      "1: {id: 190333, title: \"Ethics\", term: \"2019 Fall\", school: \"LAW\", catalog_num: \"803E\", …}\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-05-23 11:52:50\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 89\n",
      "Tags: arrays, reactjs\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 6 results for 'Ethics' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Responsible' on site 'stackoverflow'...\n",
      "Post ID: 48433783\n",
      "Post URL: https://stackoverflow.com/questions/48433783/referenceerror-fetch-is-not-defined\n",
      "Original Question: ReferenceError: fetch is not defined\n",
      "Full Question: I have this error when I compile my code in node.js, how can I fix it?\n",
      "RefernceError: fetch is not defined\n",
      "\n",
      "This is the function I am doing, it is responsible for recovering information from a specific movie database.\n",
      "function getMovieTitles(substr){  \n",
      "  pageNumber=1;\n",
      "  let url = 'https://jsonmock.hackerrank.com/api/movies/search/?Title=' + substr + \"&page=\" + pageNumber;\n",
      "  fetch(url).then((resp) => resp.json()).then(function(data) {\n",
      "    let movies = data.data;\n",
      "    let totPages = data.total_pages;\n",
      "    let sortArray = [];\n",
      "    for(let i=0; i<movies.length;i++){\n",
      "        sortArray.push(data.data[i].Title);\n",
      "     }\n",
      "    for(let i=2; i<=totPages; i++){\n",
      "           let newPage = i;\n",
      "           let url1 = 'https://jsonmock.hackerrank.com/api/movies/search/?Title=' + substr + \"&page=\" + newPage;\n",
      "\n",
      "          fetch(url1).then(function(response) {\n",
      "              var contentType = response.headers.get(\"content-type\");\n",
      "              if(contentType && contentType.indexOf(\"application/json\") !== -1) {\n",
      "                return response.json().then(function(json) {\n",
      "                  //console.log(json); //uncomment this console.log to see the JSON data.\n",
      "\n",
      "                 for(let i=0; i<json.data.length;i++){\n",
      "                    sortArray.push(json.data[i].Title);\n",
      "                 }\n",
      "\n",
      "                 if(i==totPages)console.log(sortArray.sort());\n",
      "\n",
      "                });\n",
      "              } else {\n",
      "                console.log(\"Oops, we haven't got JSON!\");\n",
      "              }\n",
      "            });\n",
      "\n",
      "        }\n",
      "  })\n",
      "  .catch(function(error) {\n",
      "    console.log(error);\n",
      "  });   \n",
      "}\n",
      "\n",
      "\n",
      "Number of Answers: 26\n",
      "Answer: N/A\n",
      "Date: 2018-01-25 02:22:21\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 961541\n",
      "Tags: javascript, node.js\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 43871637\n",
      "Post URL: https://stackoverflow.com/questions/43871637/no-access-control-allow-origin-header-is-present-on-the-requested-resource-whe\n",
      "Original Question: No &#39;Access-Control-Allow-Origin&#39; header is present on the requested resource—when trying to get data from a REST API\n",
      "Full Question: I'm trying to fetch some data from the REST API of HP Alm. It works pretty well with a small curl script—I get my data.\n",
      "Now doing that with JavaScript, fetch and ES6 (more or less) seems to be a bigger issue. I keep getting this error message:\n",
      "\n",
      "Fetch API cannot load . Response to preflight request doesn't\n",
      "pass access control check: No 'Access-Control-Allow-Origin' header is\n",
      "present on the requested resource. Origin 'http://127.0.0.1:3000' is\n",
      "therefore not allowed access. The response had HTTP status code 501.\n",
      "If an opaque response serves your needs, set the request's mode to\n",
      "'no-cors' to fetch the resource with CORS disabled.\n",
      "\n",
      "I understand that this is because I am trying to fetch that data from within my localhost and the solution should be using Cross-Origin Resource Sharing (CORS). I thought I actually did that, but somehow it either ignores what I write in the header or the problem is something else.\n",
      "So, is there an implementation issue? Am I doing it wrong? I can't check the server logs unfortunately. I'm really a bit stuck here.\n",
      "function performSignIn() {\n",
      "\n",
      "  let headers = new Headers();\n",
      "\n",
      "  headers.append('Content-Type', 'application/json');\n",
      "  headers.append('Accept', 'application/json');\n",
      "\n",
      "  headers.append('Access-Control-Allow-Origin', 'http://localhost:3000');\n",
      "  headers.append('Access-Control-Allow-Credentials', 'true');\n",
      "\n",
      "  headers.append('GET', 'POST', 'OPTIONS');\n",
      "\n",
      "  headers.append('Authorization', 'Basic ' + base64.encode(username + \":\" + password));\n",
      "\n",
      "  fetch(sign_in, {\n",
      "      //mode: 'no-cors',\n",
      "      credentials: 'include',\n",
      "      method: 'POST',\n",
      "      headers: headers\n",
      "    })\n",
      "    .then(response => response.json())\n",
      "    .then(json => console.log(json))\n",
      "    .catch(error => console.log('Authorization failed : ' + error.message));\n",
      "}\n",
      "\n",
      "I am using Chrome. I also tried using that Chrome CORS Plugin, but then I am getting another error message:\n",
      "\n",
      "The value of the 'Access-Control-Allow-Origin' header in the response\n",
      "must not be the wildcard '*' when the request's credentials mode is\n",
      "'include'. Origin 'http://127.0.0.1:3000' is therefore not allowed\n",
      "access. The credentials mode of requests initiated by the\n",
      "XMLHttpRequest is controlled by the withCredentials attribute.\n",
      "\n",
      "\n",
      "Number of Answers: 33\n",
      "Answer: N/A\n",
      "Date: 2017-05-09 15:47:47\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 3919451\n",
      "Tags: javascript, cors, fetch-api\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 2 results for 'Responsible' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Ethics' on site 'stackoverflow'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post ID: 66072158\n",
      "Post URL: https://stackoverflow.com/questions/66072158/cleaning-data-in-a-column-using-sql\n",
      "Original Question: Cleaning data in a column using SQL\n",
      "Full Question: I have a column titled \"Keywords\" that has the keywords associated with each article that is in my dataset. I wrote a query to group the articles according to their keyword so I can make a simple visualization showing which keyword is used the most. The issue is, some of the articles have a secondary keywords, and I need to write a query to filter out those secondary keywords so that just the main one remains. For instance, the \"Keywords\" column looks like this:\n",
      "KEYWORDS\n",
      "\n",
      "Policy/Ethics\n",
      "Policy/Ethics\n",
      "Policy/Ethics: Employment\n",
      "Policy/Ethics\n",
      "Policy/Ethics: Business\n",
      "\n",
      "I need help writing a query that would keep the main keywords (Policy/Ethics), but get rid of the secondary ones. I think I use CASE for this, but I'm not sure or where to begin. Any help I could get would be greatly appreciated!\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-02-06 01:56:03\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 133\n",
      "Tags: mysql, data-cleaning\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 49450740\n",
      "Post URL: https://stackoverflow.com/questions/49450740/ethics-and-readability-of-using-ternary-operator-for-method-calls\n",
      "Original Question: Ethics and readability of using ternary operator for method calls\n",
      "Full Question: The standard use of the ternary operator is, i.e.:\n",
      "a = 1 if some_condition else 2\n",
      "\n",
      "Just today, I realized something like this is perfectly legal:\n",
      "do_something() if some_condition else do_something_else()\n",
      "\n",
      "For example:\n",
      "print(1) if a == 1 else print(2)\n",
      "\n",
      "instead of:\n",
      "if a == 1:\n",
      "    print(1)\n",
      "else:\n",
      "    print(2)\n",
      "\n",
      "In my opinion, this is more compact, readable and prettier. I see that it would be harder to get return values from this type of expression (perhaps the way would be to wrap everything in parentheses). What do you think?\n",
      "P.S. I know it's not typical Q&A content, but I have never even seen this use of the ternary operator mentioned, and I think it clearly improves some aspects of Python coding.\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2018-03-23 15:26:44\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 481\n",
      "Tags: python, ternary-operator\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 66697882\n",
      "Post URL: https://stackoverflow.com/questions/66697882/adding-text-to-target-node-in-gephi-graph\n",
      "Original Question: Adding text to target node in gephi graph\n",
      "Full Question: I am trying to create a network of given data, in which source node(tweetid) target node(tweet has a link to another platform like news, youtube) edge type(a type of link like morality & ethics). I have created a network, and different indicates the different edge types morality & ethics and clustered point show twitter, news, youtube, others.\n",
      "target node\n",
      "id\n",
      "facebook     \n",
      "news\n",
      "twitter\n",
      "news\n",
      "news\n",
      "news\n",
      "\n",
      " source node\n",
      " 1194697388650370000    \n",
      " 1195602298237540000\n",
      " 1195667383182130000\n",
      " 1195673938459790000\n",
      " 1195689221970910000\n",
      "\n",
      " Edge file\n",
      " source target               edgeType \n",
      " 1194697388650370000    facebook None \n",
      " 1195602298237540000    news     None \n",
      " 1195667383182130000    Instagram Morality & Ethics \n",
      " 1195673938459790000    news     None \n",
      " 1195689221970910000    news     None\n",
      "\n",
      "\n",
      "Now, I want the highlight the target node (converging point) with a name like news, Instagram.\n",
      "How can I do it in Gephi?\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2021-03-18 21:29:56\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 383\n",
      "Tags: python, r, gephi, social-media, network-analysis\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 56625552\n",
      "Post URL: https://stackoverflow.com/questions/56625552/php-extract-second-last-value-in-array\n",
      "Original Question: PHP - Extract second last value in array\n",
      "Full Question: I have the following array:\n",
      "[\"theme\",\"1,strand\",\"Medical Ethics and Law,strandyear\",\"Year 3\"]\n",
      "\n",
      "How can I extract the second last value in the array, then the second part of that value after the comma e.g. \"Medical Ethics and Law,strandyear\"? \n",
      "This should result, for example, in 'strandyear'.\n",
      "The actual value, not the position from the end, will be different for other arrays.\n",
      "PHP 5.3.3...\n",
      "\n",
      "Number of Answers: 6\n",
      "Answer: N/A\n",
      "Date: 2019-06-17 08:10:02\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 2596\n",
      "Tags: php\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 58037099\n",
      "Post URL: https://stackoverflow.com/questions/58037099/extract-all-individual-addresses-from-a-geographical-area-includs-an-ethics-que\n",
      "Original Question: Extract all individual addresses from a geographical area (includs an ethics question)\n",
      "Full Question: Currently based in Australia, I am conducting a social research through my university. I would ideally like to access a random sample of a population - determined by a geographical area on Google Maps, OSM or other. To really have a random sample (and not self-selected volunteers answering advertisement), the only way to do so would be to have a list of all postal addresses in the said area. And pro-actively contact the selected sample within those addresses.\n",
      "Here are my questions :\n",
      "\n",
      "Is that technically feasible?\n",
      "\n",
      "If yes, would that be legal anyway? As it might be web-scraping or considered intrusive\n",
      "\n",
      "\n",
      "This question is probably going to sound very naïve - and I think I already know the answer - but I would like to confirm with more experienced people. To feel more confident saying that a 'strictly random' sample cannot be obtained ethically, and that I will need to go for a good representative sample instead.\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2019-09-21 05:46:14\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 95\n",
      "Tags: google-maps, random, openstreetmap\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 56272582\n",
      "Post URL: https://stackoverflow.com/questions/56272582/typeerror-elements-map-is-not-a-function-even-though-elements-is-an-array\n",
      "Original Question: TypeError: elements.map is not a function, even though elements is an array?\n",
      "Full Question: TypeError: elements.map is not a function.Here, elements is an array, \n",
      "function ListSelectCourses(props){\n",
      "\n",
      "    const elements = props.elements;\n",
      "    console.log(Array.isArray(elements))\n",
      "    const listElements = elements.map((element) =>\n",
      "    <option key = {element.catalog_num}>\n",
      "        {element.catalog_num}\n",
      "    </option>\n",
      "    );\n",
      "    return (\n",
      "        <h3>{props.category}\n",
      "            <select \n",
      "            value = {props.selected}\n",
      "            onChange = {props.handleChange}>\n",
      "            <option defaultValue> \n",
      "            </option>\n",
      "                {listElements}\n",
      "            </select> \n",
      "        </h3>\n",
      "    )\n",
      "};\n",
      "\n",
      "The console output is true. The data from console.log(elements): \n",
      "Array(2) \n",
      "0: {id: 190332, title: \"Legal Ethics\", term: \"2019 Fall\", school: \"LAW\", catalog_num: \"802-L\", …} \n",
      "1: {id: 190333, title: \"Ethics\", term: \"2019 Fall\", school: \"LAW\", catalog_num: \"803E\", …}\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-05-23 11:52:50\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 89\n",
      "Tags: arrays, reactjs\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 6 results for 'Ethics' on site 'stackoverflow'\n",
      "\n",
      "Searching for 'Fair' on site 'stackoverflow'...\n",
      "Post ID: 69916789\n",
      "Post URL: https://stackoverflow.com/questions/69916789/fair-scheduler-policies-fair\n",
      "Original Question: Fair Scheduler policies - FAIR\n",
      "Full Question: I'm currently trying to understand the resource allocation within a cloudera cluster. In our organization we use the FairScheduler (https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/FairScheduler.html) and I'm not sure if i understand the FAIR policy correctly.\n",
      "To summarize what I understood so far.\n",
      "FIFO: Every job gets all resources it needs, since all resources are allocated. From this point the applications have to wait for free resources and will be executed in the in the same order as they arrived.\n",
      "FAIR: Every job gets a fair share of the resources. If only 1 job arrives it gets all the available resources. If 2 Jobs arrive each job gets 1/2 of the resources.\n",
      "But what happened if job 1 needs only 25% whereas job 2 needs 75%. Will this be a problem (1 gets 25% but 2 gets 50%)? Or will this be solved with max-min fairness?\n",
      "DRF: Seeks to maximize the smallest dominant share in the system, then the second-smallest, and so on. (I know it's more complex but my question relates more to the FAIR policy)\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2021-11-10 18:24:35\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 323\n",
      "Tags: hadoop, resources, hadoop-yarn, schedule\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 76680854\n",
      "Post URL: https://stackoverflow.com/questions/76680854/java-fair-reentrant-lock-isnt-fair-in-multiple-iterations\n",
      "Original Question: Java Fair Reentrant lock isn&#39;t fair in multiple iterations\n",
      "Full Question: I am trying to write a test, in which I want to demonstrate the difference between fair and unfair Reentrant locks.\n",
      "The test uses ThreadPoolExecutor and consists of multiple iterations, each of which has the following steps:\n",
      "\n",
      "Create a fair lock to test and semaphore with 1 permit to manage the time of releasing the lock.\n",
      "Acquire the semaphore.\n",
      "Submit a task, which acquires the lock, and waits for semaphore to release.\n",
      "Submit multiple \"enumerated\" tasks, each of which tries to acquire the lock and then updates the shared AtomicInteger state.\n",
      "Release the semaphore and wait for all tasks to finish.\n",
      "\n",
      "So for the fair lock the final value of shared state have to be equal to the index of the last task.\n",
      "But the test fails in ~ 50% of all executions.\n",
      "My code looks like this:\n",
      "    @Test\n",
      "    void should_be_fair() throws InterruptedException, ExecutionException {\n",
      "        int iterationsCount = 100;\n",
      "        int waitingThreadsCount = 5;\n",
      "\n",
      "        ReentrantLock lock = new ReentrantLock(true);\n",
      "        Semaphore unlockingSemaphore = new Semaphore(1);\n",
      "        boolean wasAnyThreadUnfair = false;\n",
      "\n",
      "        for (int i = 0; i < iterationsCount; i++) {\n",
      "            unlockingSemaphore.acquire();\n",
      "            ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newFixedThreadPool(waitingThreadsCount + 1);\n",
      "            Future<?> lockingFuture = executor.submit(() -> {\n",
      "                try {\n",
      "                    lock.lock();\n",
      "                    unlockingSemaphore.acquire();\n",
      "                } catch (InterruptedException e) {\n",
      "                    throw new RuntimeException(e);\n",
      "                } finally {\n",
      "                    unlockingSemaphore.release();\n",
      "                    lock.unlock();\n",
      "                }\n",
      "            });\n",
      "            AtomicInteger sharedState = new AtomicInteger();\n",
      "            List<Future<Integer>> futures = IntStream.rangeClosed(1, waitingThreadsCount)\n",
      "                    .sequential()\n",
      "                    .mapToObj(j -> executor.submit(() -> {\n",
      "                        try {\n",
      "                            lock.lock();\n",
      "                            System.out.println(\"Acquiring lock for j=\" + j);\n",
      "                            return sharedState.updateAndGet((k) -> j);\n",
      "                        } finally {\n",
      "                            lock.unlock();\n",
      "                        }\n",
      "                    }))\n",
      "                    .toList();\n",
      "            unlockingSemaphore.release();\n",
      "            lockingFuture.get();\n",
      "            futures.forEach(f -> {\n",
      "                try {\n",
      "                    f.get();\n",
      "                } catch (InterruptedException | ExecutionException e) {\n",
      "                    throw new RuntimeException(e);\n",
      "                }\n",
      "            });\n",
      "            executor.shutdown();\n",
      "            System.out.println(\"Ended \" + i + \"-th cycle with the last index=\" + sharedState.get());\n",
      "            if (sharedState.get() != waitingThreadsCount) {\n",
      "                wasAnyThreadUnfair = true;\n",
      "                break;\n",
      "            }\n",
      "        }\n",
      "\n",
      "        Assertions.assertThat(wasAnyThreadUnfair).isFalse();\n",
      "    }\n",
      "\n",
      "Question:\n",
      "What's the problem with this test? What can I fix to get the test passed in 100% of executions?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2023-07-13 18:01:06\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 89\n",
      "Tags: java, reentrantlock\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 63069308\n",
      "Post URL: https://stackoverflow.com/questions/63069308/fair-coin-in-python\n",
      "Original Question: Fair coin in Python\n",
      "Full Question: I am trying to simulate a fair coin flip as independent bernoulli trials where the variable either goes to 1 or 0 then take the average at each trial for separate sequences.\n",
      "My problem is I am getting one sequence which looks wrong and diverges from the others (Seq_1). Can you see what I am doing wrong.\n",
      "# Parameters\n",
      "\n",
      "nSeq = 5\n",
      "nTrials = 10**3\n",
      "p=0.5 # Fair coin\n",
      "\n",
      "# Containers\n",
      "\n",
      "x = np.zeros(nTrials+1, float)\n",
      "nrange = range(nTrials+1)\n",
      "\n",
      "# Simulation\n",
      "\n",
      "for j in range(nSeq): \n",
      "    Mean_list = [0]  # re-initialize mean list for each sequence\n",
      "    for i in range(nTrials):\n",
      "        x[i+1] =  np.random.binomial(1, p) \n",
      "        xbar = np.mean(x)\n",
      "        Mean_list.append(xbar) \n",
      "        \n",
      "    plt.plot(nrange,Mean_list,label='Seq_'+str(j+1))\n",
      "plt.ylabel('Estimate of p')\n",
      "plt.xlabel('Trials')\n",
      "plt.legend(loc=0,ncol=3,fontsize='small')\n",
      "plt.show()\n",
      "\n",
      "Which then gave me this code which does not look correct. It is correct to converge to 0.5 as the coin is fair but why does seq_1 always come out different to the others?\n",
      "\n",
      "**This is trying to reproduce a graph from a book below\n",
      "\n",
      "Summary\n",
      "So to summarize. How does one generate a fair coin flip in python (using a bernoulli generated variable from numpy) then take the average of sequences that result at each flip, followed by using matplotlib to represent the findings in a graph? (Note the 'estimate of p' on the y-axis is an average of the sequence at each flip).\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2020-07-24 09:58:28\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 217\n",
      "Tags: python, numpy, matplotlib, simulation, scientific-computing\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 58356223\n",
      "Post URL: https://stackoverflow.com/questions/58356223/make-fair-loss-reliable\n",
      "Original Question: Make fair loss reliable\n",
      "Full Question: I'm studying a Distributed System.\n",
      "I'm following this book \"Introduction to Reliable and Secure Distributed Programming\" .\n",
      "In chapter 2, introduce three types of link:\n",
      "\n",
      "Fair loss (that I understand is the lighter)\n",
      "Stubborn link\n",
      "Perfect link.\n",
      "\n",
      "I saw exercises that ask to make reliable fair loss link during the algorithm creation. \n",
      "fair loss property say, that according to the book : \n",
      "\n",
      "Fair-loss: If a correct process p infinitely often sends a message m\n",
      "  to a correct process q, then q delivers m an infinite number of times\n",
      "\n",
      "So assuming that nobody process crash, why this link is so unreliable?\n",
      "Maybe the problem is duplication?\n",
      "So my real question is: \n",
      "Can I create, starting from a Fair loss link, a perfect link? \n",
      "(Obviously I want to change the fair loss, I don't want to replace it with the perfect link, otherwise, the question would be obvious)\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2019-10-12 18:34:09\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 305\n",
      "Tags: system, distributed-computing, distributed, distributed-system, distributed-programming\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 77576235\n",
      "Post URL: https://stackoverflow.com/questions/77576235/what-is-the-difference-between-fair-channel-and-fair-lossy-channel\n",
      "Original Question: what is the difference between fair channel and fair lossy channel\n",
      "Full Question: Recently I am reading the book \"fault-tolerant message passing distributed system\", and it involves these two concepts about the channel. However I can not figure out how to understand them and what  they can do, even with their descriptions in the book.\n",
      "\n",
      "Only thing I know is fair channel with different msg type but fair lossy channel with the same msg type. Anyone can help me? thanks.\n",
      "I search from GPT, and its answer is below, which seems a little different from this book.\n",
      "\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2023-11-30 08:05:55\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 25\n",
      "Tags: system, channel, distribute\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 77501303\n",
      "Post URL: https://stackoverflow.com/questions/77501303/python-simplequeue-not-fair\n",
      "Original Question: Python SimpleQueue not fair\n",
      "Full Question: The Python standard library provides two implementations for the thread-safe SimpleQueue:\n",
      "\n",
      "A pure C implementation\n",
      "A fallback Python implementation, IIUC in case Cython is not present (and because apparently it's policy to also provide a pure Python implementation)\n",
      "\n",
      "I was going through the code for both implementations in order to learn more. Among others, I learnt that the C implementation is reentrant while the Python one is not.\n",
      "However, there's something that has left me quite confused, from a comment in the code for the Python implementation:\n",
      "\n",
      "Note: while this pure Python version provides fairness\n",
      "(by using a threading.Semaphore which is itself fair, being based\n",
      "on threading.Condition), fairness is not part of the API contract.\n",
      "This allows the C version to use a different implementation.\n",
      "\n",
      "How can a thread-safe, \"FIFO queue\" not be fair? Isn't \"fairness\" guaranteed by definition, by it being FIFO in the first place?\n",
      "Also, in what way does this \"allow\" the C version to use a different implementation? I find the wording quite confusing. Does it mean that somehow this is defined as a \"potentially not fair FIFO queue\", and that reflects in the C implementation? Or something else?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2023-11-17 13:27:23\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 155\n",
      "Tags: python, queue, cython, python-multithreading\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 54450824\n",
      "Post URL: https://stackoverflow.com/questions/54450824/matplotlib-plot-histogram-of-fair-die\n",
      "Original Question: Matplotlib plot histogram of fair die\n",
      "Full Question: I'm trying to display a histogram of the probability density of throwing a fair die. Basically there should be 6 bars and each with height 1/6, equally spaced. I tried this:\n",
      "fair = np.array([1, 2, 3, 4, 5, 6]*100)\n",
      "plt.hist(fair, density=True, label='Fair Die')\n",
      "plt.show()\n",
      "\n",
      "and I also tried this\n",
      "plt.hist(fair, bins=11, density=True, label='Fair Die', align='mid')\n",
      "\n",
      "but it doesn't seem to work. I don't understand why the hist command doesn't make the correct histogram by default, it is such a simple histogram.\n",
      "\n",
      "Number of Answers: 2\n",
      "Answer: N/A\n",
      "Date: 2019-01-31 00:57:38\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 545\n",
      "Tags: python, python-3.x, matplotlib, histogram\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 50407212\n",
      "Post URL: https://stackoverflow.com/questions/50407212/spark-application-fair-scheduling\n",
      "Original Question: Spark Application FAIR Scheduling\n",
      "Full Question: I have a job who iterates over the a table columns to get the distinct values of each one. The queries takes about 6 seconds each one but they don't use the full CPU's. That's why I have decided to use the FAIR scheduling within an Application so the resources can be fully used. Actually this application have 4 cores and 10 Gb ram. \n",
      "I have added to my spark spark-defaults.conf file the following lines:\n",
      "spark.scheduler.mode FAIR\n",
      "spark.scheduler.allocation.file /bin/spark/pools.xml\n",
      "\n",
      "I have created the following pool:\n",
      "<pool name=\"filters\">\n",
      "<schedulingMode>FAIR</schedulingMode>\n",
      "<weight>1000</weight>\n",
      "<minShare>0</minShare>\n",
      "</pool>\n",
      "\n",
      "And this is my code:\n",
      "List<ColumnMetadata> fields = getCategoryFieldsFromViewMetadata(...);\n",
      "Dataset<Row> dsCube = sqlContext.sql(\"...\");\n",
      "\n",
      "dsCube = dsCube\n",
      "        .select(JavaConversions.asScalaBuffer(filterColumns))\n",
      "        .persist(StorageLevel.MEMORY_ONLY());\n",
      "\n",
      "dsCube.createOrReplaceTempView(\"filter_temp\");\n",
      "\n",
      "sqlContext.sparkContext().setLocalProperty(\"spark.scheduler.pool\", \"filters\");\n",
      "\n",
      "fields.parallelStream().forEach((ColumnMetadata field) -> {\n",
      "    Dataset<Row> temp = sqlContext.sql(\"select distinct tenant_id, user_domain, cube_name, field, value \"\n",
      "                        +\"from filter_temp\");\n",
      "    saveDataFrameToMySQL(\"analytics_cubes_filters\", temp, SaveMode.Append); //Here I save the results to a MySQL table.\n",
      "});\n",
      "sqlContext.sparkContext().setLocalProperty(\"spark.scheduler.pool\", null);\n",
      "\n",
      "The filters pool is being used, I can see it in the spark application GUI and the jobs are executed in parallel, but if before, each query was executed in FIFO mode in 6 seconds now using the FAIR mode 4 parallel queries are executed in 24 seconds. I have checked the CPU usage and looks like before when the FIFO mode was being used.\n",
      "Am I missing something?\n",
      "\n",
      "Number of Answers: 0\n",
      "Answer: N/A\n",
      "Date: 2018-05-18 10:42:37\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 298\n",
      "Tags: java, apache-spark\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): No\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 42527849\n",
      "Post URL: https://stackoverflow.com/questions/42527849/spark-schedule-fifo-or-fair\n",
      "Original Question: Spark Schedule: FIFO or FAIR?\n",
      "Full Question: How to choose Spark Scheduler: FIFO or FAIR? \n",
      "What is the different between Spark Scheduler and YARN Scheduler? \n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2017-03-01 11:23:35\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 9953\n",
      "Tags: apache-spark, hadoop-yarn\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Post ID: 63518754\n",
      "Post URL: https://stackoverflow.com/questions/63518754/rxjava3-rximmediateschedulerrule-executorscheduler-fair-parameter\n",
      "Original Question: RxJava3 RxImmediateSchedulerRule ExecutorScheduler fair parameter\n",
      "Full Question: RxJava rule for testing with schedulers was\n",
      "import io.reactivex.Scheduler\n",
      "import io.reactivex.android.plugins.RxAndroidPlugins\n",
      "import io.reactivex.internal.schedulers.ExecutorScheduler\n",
      "import io.reactivex.plugins.RxJavaPlugins\n",
      "import org.junit.rules.TestRule\n",
      "import org.junit.runner.Description\n",
      "import org.junit.runners.model.Statement\n",
      "import java.util.concurrent.Executor\n",
      "\n",
      "class RxImmediateSchedulerRule : TestRule {\n",
      "\n",
      "    private val immediate = object : Scheduler() {\n",
      "\n",
      "        override fun createWorker(): Worker {\n",
      "            return ExecutorScheduler.ExecutorWorker(Executor { it.run() }, true)\n",
      "        }\n",
      "    }\n",
      "\n",
      "//    private val immediate = Schedulers.trampoline()\n",
      "\n",
      "    override fun apply(base: Statement, description: Description): Statement {\n",
      "        return object : Statement() {\n",
      "            @Throws(Throwable::class)\n",
      "            override fun evaluate() {\n",
      "                RxJavaPlugins.setInitIoSchedulerHandler { immediate }\n",
      "                RxJavaPlugins.setInitComputationSchedulerHandler { immediate }\n",
      "                RxJavaPlugins.setInitNewThreadSchedulerHandler { immediate }\n",
      "                RxJavaPlugins.setInitSingleSchedulerHandler { immediate }\n",
      "                RxAndroidPlugins.setInitMainThreadSchedulerHandler { immediate }\n",
      "\n",
      "                try {\n",
      "                    base.evaluate()\n",
      "                } finally {\n",
      "                    RxJavaPlugins.reset()\n",
      "                    RxAndroidPlugins.reset()\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Now with RxJava3\n",
      "ExecutorScheduler.ExecutorWorker(Executor { it.run() }, true, true)\n",
      "\n",
      "Second parameter here is called fair but there is no JavaDoc or explanation for this parameter in ExecutorScheduler class. Wha is fair paramater used for, and when it should be used?\n",
      "\n",
      "Number of Answers: 1\n",
      "Answer: N/A\n",
      "Date: 2020-08-21 09:52:15\n",
      "Number of votes (on answer): N/A\n",
      "Number of views: 709\n",
      "Tags: android, unit-testing, rx-java3\n",
      "Topic: stackoverflow\n",
      "Answered (Yes/No): Yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Found 10 results for 'Fair' on site 'stackoverflow'\n",
      "\n",
      "Results have been saved to 'stackoverflow_search_results.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of search terms\n",
    "search_terms = [\n",
    "    \"Algorithmic\",\n",
    "    \"Fairness\",\n",
    "    \"Bias\",\n",
    "    \"Discrimination\"\n",
    "    \"Ethics\",\n",
    "    \"Responsible\",\n",
    "    \"Ethics\",\n",
    "    \"Fair\"\n",
    "]\n",
    "\n",
    "# Only Stack Overflow site\n",
    "sites = [\n",
    "    \"stackoverflow\"\n",
    "]\n",
    "\n",
    "# Function to search StackExchange for a given keyword on a specific site\n",
    "def search_stackexchange(keyword, site):\n",
    "    url = \"https://api.stackexchange.com/2.3/search/advanced\"\n",
    "    params = {\n",
    "        'order': 'desc',\n",
    "        'sort': 'relevance',\n",
    "        'q': keyword,\n",
    "        'site': site,\n",
    "        'filter': 'withbody'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            return response.json()\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Unable to decode JSON for keyword '{keyword}' on site '{site}'\")\n",
    "            return {}\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code} for keyword '{keyword}' on site '{site}'\")\n",
    "        return {}\n",
    "\n",
    "# Function to filter results from 2017 onwards\n",
    "def filter_by_date(items):\n",
    "    filtered_items = []\n",
    "    for item in items:\n",
    "        creation_date = datetime.datetime.fromtimestamp(item['creation_date'])\n",
    "        if creation_date.year >= 2017:\n",
    "            filtered_items.append(item)\n",
    "    return filtered_items\n",
    "\n",
    "# Function to convert HTML to readable text\n",
    "def html_to_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "    for term in search_terms:\n",
    "        for site in sites:\n",
    "            print(f\"Searching for '{term}' on site '{site}'...\")\n",
    "            result = search_stackexchange(term, site)\n",
    "            if result:\n",
    "                filtered_items = filter_by_date(result.get('items', []))\n",
    "                for item in filtered_items:\n",
    "                    question_id = item['question_id']\n",
    "                    question_url = item['link']\n",
    "                    original_question = item['title']\n",
    "                    full_question = html_to_text(item['body'])\n",
    "                    creation_date = datetime.datetime.fromtimestamp(item['creation_date']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    number_of_views = item['view_count']\n",
    "                    tags = ', '.join(item['tags'])\n",
    "                    topic = site\n",
    "                    is_answered = \"Yes\" if item['is_answered'] else \"No\"\n",
    "                    \n",
    "                    if 'answers' in item:\n",
    "                        for answer in item['answers']:\n",
    "                            result_entry = {\n",
    "                                \"Post ID\": question_id,\n",
    "                                \"PostURL\": question_url,\n",
    "                                \"Original Question\": original_question,\n",
    "                                \"Full Question\": full_question,\n",
    "                                \"Number of Answers\": item['answer_count'],\n",
    "                                \"Answer\": html_to_text(answer['body']),\n",
    "                                \"Date\": creation_date,\n",
    "                                \"Number of votes (on answer)\": answer['score'],\n",
    "                                \"Number of views\": number_of_views,\n",
    "                                \"Tags\": tags,\n",
    "                                \"Topic\": topic,\n",
    "                                \"Answered (Yes/No)\": is_answered\n",
    "                            }\n",
    "                            results.append(result_entry)\n",
    "                            # Print the results in the console\n",
    "                            print(f\"Post ID: {result_entry['Post ID']}\")\n",
    "                            print(f\"Post URL: {result_entry['PostURL']}\")\n",
    "                            print(f\"Original Question: {result_entry['Original Question']}\")\n",
    "                            print(f\"Full Question: {result_entry['Full Question']}\")\n",
    "                            print(f\"Number of Answers: {result_entry['Number of Answers']}\")\n",
    "                            print(f\"Answer: {result_entry['Answer']}\")\n",
    "                            print(f\"Date: {result_entry['Date']}\")\n",
    "                            print(f\"Number of votes (on answer): {result_entry['Number of votes (on answer)']}\")\n",
    "                            print(f\"Number of views: {result_entry['Number of views']}\")\n",
    "                            print(f\"Tags: {result_entry['Tags']}\")\n",
    "                            print(f\"Topic: {result_entry['Topic']}\")\n",
    "                            print(f\"Answered (Yes/No): {result_entry['Answered (Yes/No)']}\")\n",
    "                            print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "                    else:\n",
    "                        result_entry = {\n",
    "                            \"Post ID\": question_id,\n",
    "                            \"PostURL\": question_url,\n",
    "                            \"Original Question\": original_question,\n",
    "                            \"Full Question\": full_question,\n",
    "                            \"Number of Answers\": item['answer_count'],\n",
    "                            \"Answer\": \"N/A\",\n",
    "                            \"Date\": creation_date,\n",
    "                            \"Number of votes (on answer)\": \"N/A\",\n",
    "                            \"Number of views\": number_of_views,\n",
    "                            \"Tags\": tags,\n",
    "                            \"Topic\": topic,\n",
    "                            \"Answered (Yes/No)\": is_answered\n",
    "                        }\n",
    "                        results.append(result_entry)\n",
    "                        # Print the results in the console\n",
    "                        print(f\"Post ID: {result_entry['Post ID']}\")\n",
    "                        print(f\"Post URL: {result_entry['PostURL']}\")\n",
    "                        print(f\"Original Question: {result_entry['Original Question']}\")\n",
    "                        print(f\"Full Question: {result_entry['Full Question']}\")\n",
    "                        print(f\"Number of Answers: {result_entry['Number of Answers']}\")\n",
    "                        print(f\"Answer: {result_entry['Answer']}\")\n",
    "                        print(f\"Date: {result_entry['Date']}\")\n",
    "                        print(f\"Number of votes (on answer): {result_entry['Number of votes (on answer)']}\")\n",
    "                        print(f\"Number of views: {result_entry['Number of views']}\")\n",
    "                        print(f\"Tags: {result_entry['Tags']}\")\n",
    "                        print(f\"Topic: {result_entry['Topic']}\")\n",
    "                        print(f\"Answered (Yes/No): {result_entry['Answered (Yes/No)']}\")\n",
    "                        print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "                print(f\"Found {len(filtered_items)} results for '{term}' on site '{site}'\\n\")\n",
    "            else:\n",
    "                print(f\"No results found for '{term}' on site '{site}'\\n\")\n",
    "\n",
    "    # Save results to an Excel file\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"StackOverflow Search Results\"\n",
    "    headers = [\"Post ID\", \"PostURL\", \"Original Question\", \"Full Question\", \"Number of Answers\", \"Answer\", \"Date\", \"Number of votes (on answer)\", \"Number of views\", \"Tags\", \"Topic\", \"Answered (Yes/No)\"]\n",
    "    ws.append(headers)\n",
    "    \n",
    "    for result in results:\n",
    "        ws.append([\n",
    "            result[\"Post ID\"],\n",
    "            result[\"PostURL\"],\n",
    "            result[\"Original Question\"],\n",
    "            result[\"Full Question\"],\n",
    "            result[\"Number of Answers\"],\n",
    "            result[\"Answer\"],\n",
    "            result[\"Date\"],\n",
    "            result[\"Number of votes (on answer)\"],\n",
    "            result[\"Number of views\"],\n",
    "            result[\"Tags\"],\n",
    "            result[\"Topic\"],\n",
    "            result[\"Answered (Yes/No)\"]\n",
    "        ])\n",
    "\n",
    "    wb.save(\"stackoverflow_search_results.xlsx\")\n",
    "    print(\"Results have been saved to 'stackoverflow_search_results.xlsx'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd523d08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
